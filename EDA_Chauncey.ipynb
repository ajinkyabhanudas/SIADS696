{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Project Overview\n",
    "\n",
    "The goal of the project is to provide Youtube content creators with a way to gauge how effective a video title will be and to provide insight on which titles work best. Video titles are one of the main factors that determine whether people decide to click on a video or not. Coming up with a ‘formula’ for creating effective video titles would be advantageous to content creators. Phase I Our goal is to automate this process by using unsupervised & supervised learning to determine if there is a relationship between the structure of a title and the number of views.\n",
    "\n",
    "We reviewed similar projects as part of our literature review and found most of the approaches that did ........ \n",
    "\n",
    "The common finding was that ..... \n",
    "\n",
    "We intend to use unsupervised learning to extract an underlying structure of video titles and use those features for prediction. This will require us to represent the features of video titles appropriately such that those features can be used by ML algorithms.  \n",
    "\n",
    "- sarcasm score\n",
    "- boring score\n",
    "- remove outliers  UMAP & LOF\n",
    "- choosing top_n vs bottom_n to reduce noise from average performing vidoes\n",
    "- build multiple model for sub groups as titles vary too much across broad categories \n",
    "- becasuse it was found that previous video views are the strongest predictor of future views, try restricting to channels with low subscriber count\n",
    "- views/subscriber count (normalizes views by subscriber count to estimate new views)\n",
    "- comments/subscribers   (highly engaged viewers)\n",
    "- change target to engagement which is a compination of views, likes and comments\n",
    "- use topic modeling and calculate similarity to trending topics or topics in video comments\n",
    "\n",
    "\n",
    "In this notebook, I will focus on extracting and preparing the data to be used by the ML algorithms. I will also establish the baseline model performance by training some naive regressors and a linear regressor model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction & Exploration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Extraction\n",
    "\n",
    "Extracting the data from all json files and combining into a dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of channels 86\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "dir = 'data'\n",
    "path = os.path.join(dir, '**/*.json')\n",
    "file_list = glob.glob(path)\n",
    "print('Total number of channels ' + str(len(file_list)))\n",
    "\n",
    "dfs = list()\n",
    "\n",
    "for file in file_list:\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    channel_id, stats = data.popitem()\n",
    "    pchannel_stats = stats[\"channel_statistics\"]\n",
    "    video_stats = stats[\"video_data\"]\n",
    "    vids = video_stats.items()\n",
    "    stats = []\n",
    "    for vid in vids:\n",
    "        video_id = vid[0]\n",
    "        title = vid[1][\"title\"]\n",
    "        try:\n",
    "            views = vid[1][\"viewCount\"]\n",
    "            likes = vid[1][\"likeCount\"]\n",
    "            duration = vid[1]['duration']\n",
    "            tags = vid[1]['tags']\n",
    "            description = vid[1]['description']\n",
    "            comments = vid[1][\"commentCount\"]\n",
    "            channel = vid[1]['channelTitle']\n",
    "            published = vid[1]['publishedAt'].split('T')[0]\n",
    "        except:\n",
    "            pass\n",
    "        cat = os.path.dirname(file).split('\\\\')[1]\n",
    "        stats.append([title,views, published, likes, comments, duration, tags, description, channel, cat])\n",
    "    vid_df = pd.DataFrame(stats, columns=[\"title\",\"views\", 'published',\"likes\",\"comments\", 'duration','tag','description', 'channel', 'category'])\n",
    "    dfs.append(vid_df)\n",
    "    \n",
    "    \n",
    "df = pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>views</th>\n",
       "      <th>published</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>duration</th>\n",
       "      <th>tag</th>\n",
       "      <th>description</th>\n",
       "      <th>channel</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bartending, Improv, and Other Trends of 2011 |...</td>\n",
       "      <td>438729</td>\n",
       "      <td>2021-12-22</td>\n",
       "      <td>17207</td>\n",
       "      <td>628</td>\n",
       "      <td>PT10M1S</td>\n",
       "      <td>[Collegehumor, CH originals, comedy, sketch co...</td>\n",
       "      <td>The news crew talks corgi butts, National Call...</td>\n",
       "      <td>CollegeHumor</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Inspector Gadget's Death Sparks Oscar Buzz | N...</td>\n",
       "      <td>479899</td>\n",
       "      <td>2021-11-10</td>\n",
       "      <td>16614</td>\n",
       "      <td>605</td>\n",
       "      <td>PT5M</td>\n",
       "      <td>[Collegehumor, CH originals, comedy, sketch co...</td>\n",
       "      <td>Jeffrey Self and Grant question the wetness of...</td>\n",
       "      <td>CollegeHumor</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Delicious Kitchen Fire Caramelizes Dozens of P...</td>\n",
       "      <td>740322</td>\n",
       "      <td>2021-08-25</td>\n",
       "      <td>28629</td>\n",
       "      <td>779</td>\n",
       "      <td>PT4M33S</td>\n",
       "      <td>[Collegehumor, CH originals, comedy, sketch co...</td>\n",
       "      <td>Stamps Dotcom &amp; Marc Maron report that Russian...</td>\n",
       "      <td>CollegeHumor</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Handshakes For Men, Hugs For Women | No Laugh ...</td>\n",
       "      <td>1642663</td>\n",
       "      <td>2021-07-14</td>\n",
       "      <td>71402</td>\n",
       "      <td>1507</td>\n",
       "      <td>PT8M16S</td>\n",
       "      <td>[Collegehumor, CH originals, comedy, sketch co...</td>\n",
       "      <td>Amy shows off some new dances. Brennan is a 12...</td>\n",
       "      <td>CollegeHumor</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True Stories From the CollegeHumor Office | No...</td>\n",
       "      <td>1828336</td>\n",
       "      <td>2021-06-02</td>\n",
       "      <td>66660</td>\n",
       "      <td>1368</td>\n",
       "      <td>PT6M4S</td>\n",
       "      <td>[Collegehumor, CH originals, comedy, sketch co...</td>\n",
       "      <td>Trapp &amp; Katie read a riveting report from the ...</td>\n",
       "      <td>CollegeHumor</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title    views   published  \\\n",
       "0  Bartending, Improv, and Other Trends of 2011 |...   438729  2021-12-22   \n",
       "1  Inspector Gadget's Death Sparks Oscar Buzz | N...   479899  2021-11-10   \n",
       "2  Delicious Kitchen Fire Caramelizes Dozens of P...   740322  2021-08-25   \n",
       "3  Handshakes For Men, Hugs For Women | No Laugh ...  1642663  2021-07-14   \n",
       "4  True Stories From the CollegeHumor Office | No...  1828336  2021-06-02   \n",
       "\n",
       "   likes comments duration                                                tag  \\\n",
       "0  17207      628  PT10M1S  [Collegehumor, CH originals, comedy, sketch co...   \n",
       "1  16614      605     PT5M  [Collegehumor, CH originals, comedy, sketch co...   \n",
       "2  28629      779  PT4M33S  [Collegehumor, CH originals, comedy, sketch co...   \n",
       "3  71402     1507  PT8M16S  [Collegehumor, CH originals, comedy, sketch co...   \n",
       "4  66660     1368   PT6M4S  [Collegehumor, CH originals, comedy, sketch co...   \n",
       "\n",
       "                                         description       channel category  \n",
       "0  The news crew talks corgi butts, National Call...  CollegeHumor   Comedy  \n",
       "1  Jeffrey Self and Grant question the wetness of...  CollegeHumor   Comedy  \n",
       "2  Stamps Dotcom & Marc Maron report that Russian...  CollegeHumor   Comedy  \n",
       "3  Amy shows off some new dances. Brennan is a 12...  CollegeHumor   Comedy  \n",
       "4  Trapp & Katie read a riveting report from the ...  CollegeHumor   Comedy  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>views</th>\n",
       "      <th>published</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>duration</th>\n",
       "      <th>tag</th>\n",
       "      <th>description</th>\n",
       "      <th>channel</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33691</th>\n",
       "      <td>Downward Dog - Downward Facing Dog Yoga Pose</td>\n",
       "      <td>1327691</td>\n",
       "      <td>2012-12-12</td>\n",
       "      <td>13997</td>\n",
       "      <td>565</td>\n",
       "      <td>PT7M58S</td>\n",
       "      <td>[downward dog, down dog, downward facing dog, ...</td>\n",
       "      <td>Learn Downward Dog yoga pose with Adriene. If ...</td>\n",
       "      <td>Yoga With Adriene</td>\n",
       "      <td>Yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33692</th>\n",
       "      <td>Reclined Twist Yoga Pose - Yoga With Adriene</td>\n",
       "      <td>162174</td>\n",
       "      <td>2012-11-14</td>\n",
       "      <td>2397</td>\n",
       "      <td>116</td>\n",
       "      <td>PT8M40S</td>\n",
       "      <td>[yoga, adriene mishler, yoga with adriene, yog...</td>\n",
       "      <td>Learn the Reclined Twist Yoga Pose with Adrien...</td>\n",
       "      <td>Yoga With Adriene</td>\n",
       "      <td>Yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33693</th>\n",
       "      <td>Corpse Pose - Yoga With Adriene</td>\n",
       "      <td>336507</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>4589</td>\n",
       "      <td>249</td>\n",
       "      <td>PT9M27S</td>\n",
       "      <td>[yoga for beginners, yoga with adriene, founda...</td>\n",
       "      <td>Learn how to do the Corpse Pose with Adriene! ...</td>\n",
       "      <td>Yoga With Adriene</td>\n",
       "      <td>Yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33694</th>\n",
       "      <td>Extended Child's Pose - Yoga With Adriene</td>\n",
       "      <td>1451610</td>\n",
       "      <td>2012-10-24</td>\n",
       "      <td>11649</td>\n",
       "      <td>373</td>\n",
       "      <td>PT6M14S</td>\n",
       "      <td>[extended child's pose, yoga for beginners, ch...</td>\n",
       "      <td>Learn Extended Child's Pose with Adriene! This...</td>\n",
       "      <td>Yoga With Adriene</td>\n",
       "      <td>Yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33695</th>\n",
       "      <td>Runner's Lunge - Foundations of Yoga</td>\n",
       "      <td>247577</td>\n",
       "      <td>2012-10-10</td>\n",
       "      <td>3364</td>\n",
       "      <td>165</td>\n",
       "      <td>PT6M4S</td>\n",
       "      <td>[yoga for beginners, yoga with adriene, adrien...</td>\n",
       "      <td>Learn Runner's Lunge with Adriene! (Not just f...</td>\n",
       "      <td>Yoga With Adriene</td>\n",
       "      <td>Yoga</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              title    views   published  \\\n",
       "33691  Downward Dog - Downward Facing Dog Yoga Pose  1327691  2012-12-12   \n",
       "33692  Reclined Twist Yoga Pose - Yoga With Adriene   162174  2012-11-14   \n",
       "33693               Corpse Pose - Yoga With Adriene   336507  2012-10-31   \n",
       "33694     Extended Child's Pose - Yoga With Adriene  1451610  2012-10-24   \n",
       "33695          Runner's Lunge - Foundations of Yoga   247577  2012-10-10   \n",
       "\n",
       "       likes comments duration  \\\n",
       "33691  13997      565  PT7M58S   \n",
       "33692   2397      116  PT8M40S   \n",
       "33693   4589      249  PT9M27S   \n",
       "33694  11649      373  PT6M14S   \n",
       "33695   3364      165   PT6M4S   \n",
       "\n",
       "                                                     tag  \\\n",
       "33691  [downward dog, down dog, downward facing dog, ...   \n",
       "33692  [yoga, adriene mishler, yoga with adriene, yog...   \n",
       "33693  [yoga for beginners, yoga with adriene, founda...   \n",
       "33694  [extended child's pose, yoga for beginners, ch...   \n",
       "33695  [yoga for beginners, yoga with adriene, adrien...   \n",
       "\n",
       "                                             description            channel  \\\n",
       "33691  Learn Downward Dog yoga pose with Adriene. If ...  Yoga With Adriene   \n",
       "33692  Learn the Reclined Twist Yoga Pose with Adrien...  Yoga With Adriene   \n",
       "33693  Learn how to do the Corpse Pose with Adriene! ...  Yoga With Adriene   \n",
       "33694  Learn Extended Child's Pose with Adriene! This...  Yoga With Adriene   \n",
       "33695  Learn Runner's Lunge with Adriene! (Not just f...  Yoga With Adriene   \n",
       "\n",
       "      category  \n",
       "33691     Yoga  \n",
       "33692     Yoga  \n",
       "33693     Yoga  \n",
       "33694     Yoga  \n",
       "33695     Yoga  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title          0\n",
       "views          0\n",
       "published      0\n",
       "likes          0\n",
       "comments       0\n",
       "duration       0\n",
       "tag            0\n",
       "description    0\n",
       "channel        0\n",
       "category       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()\n",
    "#df.views = (df.views).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                  object\n",
       "views                  object\n",
       "published      datetime64[ns]\n",
       "likes                  object\n",
       "comments               object\n",
       "duration               object\n",
       "tag                    object\n",
       "description            object\n",
       "channel                object\n",
       "category               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['views'] = df[\"views\"]. apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33696, 10)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.published = pd.to_datetime(df.published, format='%Y-%m-%d')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15873</th>\n",
       "      <td>Ed Sheeran - Shape of You (Official Music Video)</td>\n",
       "      <td>5809870270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15893</th>\n",
       "      <td>Ed Sheeran - Thinking Out Loud (Official Music...</td>\n",
       "      <td>3499179932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15848</th>\n",
       "      <td>Ed Sheeran - Perfect (Official Music Video)</td>\n",
       "      <td>3256243151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15695</th>\n",
       "      <td>Bruno Mars - The Lazy Song (Official Music Video)</td>\n",
       "      <td>2416952328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15658</th>\n",
       "      <td>Bruno Mars - That’s What I Like [Official Musi...</td>\n",
       "      <td>2061152302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15705</th>\n",
       "      <td>Bruno Mars - Just The Way You Are (Official Mu...</td>\n",
       "      <td>1752542816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15669</th>\n",
       "      <td>Bruno Mars - 24K Magic (Official Music Video)</td>\n",
       "      <td>1532258215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15882</th>\n",
       "      <td>Ed Sheeran - Photograph (Official Music Video)</td>\n",
       "      <td>1238010919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15676</th>\n",
       "      <td>Bruno Mars - When I Was Your Man (Official Mus...</td>\n",
       "      <td>1182488125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15701</th>\n",
       "      <td>Bruno Mars - Grenade (Official Music Video)</td>\n",
       "      <td>1098346906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title       views\n",
       "15873   Ed Sheeran - Shape of You (Official Music Video)  5809870270\n",
       "15893  Ed Sheeran - Thinking Out Loud (Official Music...  3499179932\n",
       "15848        Ed Sheeran - Perfect (Official Music Video)  3256243151\n",
       "15695  Bruno Mars - The Lazy Song (Official Music Video)  2416952328\n",
       "15658  Bruno Mars - That’s What I Like [Official Musi...  2061152302\n",
       "15705  Bruno Mars - Just The Way You Are (Official Mu...  1752542816\n",
       "15669      Bruno Mars - 24K Magic (Official Music Video)  1532258215\n",
       "15882     Ed Sheeran - Photograph (Official Music Video)  1238010919\n",
       "15676  Bruno Mars - When I Was Your Man (Official Mus...  1182488125\n",
       "15701        Bruno Mars - Grenade (Official Music Video)  1098346906"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def top10():\n",
    "    \n",
    "    \"\"\"This function sorts the data by views and title and selects the top 10 titles\"\"\"\n",
    "    \n",
    "    df_sorted = df.sort_values(['views','title'], ascending=[False,True])[:10]\n",
    "    \n",
    "    return df_sorted[['title','views']]\n",
    "\n",
    "top10()  # mostly popular songs at the top. We will probably have to remove this category "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>10-Minute Dance Cardio Workout With Charlize G...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11283</th>\n",
       "      <td>10-Minute Feel-Good Standing Workout With Rach...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11286</th>\n",
       "      <td>10-Minute, No-Equipment Cardio HIIT With Ranei...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16129</th>\n",
       "      <td>ROUND 2 LDN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15708</th>\n",
       "      <td>Ed Sheeran, Pokémon - Celestial [Official Video]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23908</th>\n",
       "      <td>SMASHING COLOR FILLED BALLOON AT BOSTON FENWAY...</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19013</th>\n",
       "      <td>FDI net inflows slow for 4th straight month in...</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18472</th>\n",
       "      <td>Pamilya ng nasagasaang street sweeper, desidid...</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18986</th>\n",
       "      <td>Manhit: It is govt's role to protect PH mariti...</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18639</th>\n",
       "      <td>Hottest new films to stream from thrillers to ...</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  views\n",
       "11284  10-Minute Dance Cardio Workout With Charlize G...      0\n",
       "11283  10-Minute Feel-Good Standing Workout With Rach...      0\n",
       "11286  10-Minute, No-Equipment Cardio HIIT With Ranei...      0\n",
       "16129                                        ROUND 2 LDN      0\n",
       "15708   Ed Sheeran, Pokémon - Celestial [Official Video]      9\n",
       "23908  SMASHING COLOR FILLED BALLOON AT BOSTON FENWAY...    305\n",
       "19013  FDI net inflows slow for 4th straight month in...    365\n",
       "18472  Pamilya ng nasagasaang street sweeper, desidid...    377\n",
       "18986  Manhit: It is govt's role to protect PH mariti...    399\n",
       "18639  Hottest new films to stream from thrillers to ...    458"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bottom10():\n",
    "    \n",
    "    \"\"\"This function sorts the data by views and title and selects the top 10 titles\"\"\"\n",
    "    \n",
    "    df_sorted = df.sort_values(['views','title'], ascending=[True,True])[:10]\n",
    "    \n",
    "    return df_sorted[['title','views']]\n",
    "\n",
    "bottom10() # we will have to consider removing titles with no views. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting our data into train, dev and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26956 3370 3370\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data in 80%, 10%, 10% train, dev and test sets\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "train_df, dev_df, test_df = np.split(df.sample(frac=1, random_state=RANDOM_SEED),[int(.8*len(df)), int(.9*len(df))])\n",
    "\n",
    "print(len(train_df), len(dev_df), len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the titles to features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# fitting a vectorizer\n",
    "# We will use 50 for min_df to ensure that a word shows up at least 50 times. \n",
    "# We will also specify that english stop words are to be removed and \n",
    "# We will use unigrams and bigrams\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=50,stop_words='english',ngram_range=(1, 2))\n",
    "X_train = vectorizer.fit_transform(train_df.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26956, 619)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape  # We found 619 word features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting list of labels \n",
    "y_train = list(train_df.views)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit a unigram and bigram LinearRegression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating development data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev = vectorizer.transform(dev_df.title)\n",
    "y_dev = list(dev_df.views)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Dummy Classifiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyRegressor(strategy='median')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_clf_mean = DummyRegressor(strategy=\"mean\")\n",
    "dummy_clf_mean.fit(X_train, y_train)\n",
    "dummy_clf_median = DummyRegressor(strategy=\"median\")\n",
    "dummy_clf_median.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating all the predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_dev_preds = reg.predict(X_dev)\n",
    "mean_dev_preds = dummy_clf_mean.predict(X_dev)\n",
    "median_dev_preds = dummy_clf_median.predict(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_mse = mean_squared_error(y_dev, lr_dev_preds)\n",
    "mean_mse = mean_squared_error(y_dev, mean_dev_preds)\n",
    "median_mse = mean_squared_error(y_dev, median_dev_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3613698765604540.0\n",
      "3836618484685100.0\n",
      "3851671859597287.5\n"
     ]
    }
   ],
   "source": [
    "print(lr_mse)\n",
    "print(mean_mse)\n",
    "print(median_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "467f60c46b88ea196e8e4e51716c4f14b05141d893e1660e0038b81da854c476"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
